import os
from openai import OpenAI
from langchain_community.vectorstores.faiss import FAISS
from langchain_huggingface import HuggingFaceEmbeddings
import torch

# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ MFECGPT API
# os.environ["MFEC_API_KEY"] = "sk-"
client = OpenAI(
    base_url="https://gpt.mfec.co.th/litellm",
    api_key=os.environ["MFEC_API_KEY"],
)

# ‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏ß‡∏Å‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏ê‡∏≤‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ
embedding_model = HuggingFaceEmbeddings(
    model_name="intfloat/multilingual-e5-base",
    model_kwargs={"device": "cuda" if torch.cuda.is_available() else "cpu"}
)
VECTOR_PATH = "./database/vectorstore_db"
vectorstore = FAISS.load_local(VECTOR_PATH, embedding_model, allow_dangerous_deserialization=True)

def ask_mfecgpt(chat_history: str, question: str) -> str:
    relevant_docs = vectorstore.similarity_search(question, k=5)

    if not relevant_docs:
        return ("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏Ñ‡∏•‡∏±‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì\n\n"
                "üìå ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏° ‡∏´‡∏£‡∏∑‡∏≠‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡πÉ‡∏´‡πâ‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô‡∏°‡∏≤‡∏Å‡∏Ç‡∏∂‡πâ‡∏ô\n"
                "üß† ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á: ‡∏•‡∏≠‡∏á‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏≥‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç ‡πÄ‡∏ä‡πà‡∏ô ‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà ‡∏´‡∏£‡∏∑‡∏≠‡∏Ñ‡∏≥‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ó‡∏≤‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á")

    context = "\n\n".join(doc.page_content for doc in relevant_docs)

    agentRole = f"""
    ‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏≠‡∏±‡∏à‡∏â‡∏£‡∏¥‡∏¢‡∏∞‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏ö‡∏∏‡∏Ñ‡∏•‡∏¥‡∏Å‡πÉ‡∏à‡∏î‡∏µ ‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏¥‡∏ï‡∏£ ‡πÅ‡∏•‡∏∞‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡πÄ‡∏™‡∏°‡∏≠

    ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏Ç‡∏≠‡∏á‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏î‡πâ‡∏ß‡∏¢‡∏†‡∏≤‡∏©‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏á‡πà‡∏≤‡∏¢ ‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏±‡∏ô‡πÄ‡∏≠‡∏á ‡πÅ‡∏•‡∏∞‡∏™‡∏∏‡∏†‡∏≤‡∏û
    ‡∏´‡∏≤‡∏Å‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏à‡∏≤‡∏Å‡∏ö‡∏£‡∏¥‡∏ö‡∏ó ‡πÉ‡∏´‡πâ‡∏ï‡∏≠‡∏ö‡πÇ‡∏î‡∏¢‡∏™‡∏£‡∏∏‡∏õ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤ ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÅ‡∏à‡πâ‡∏á‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á
    ‡∏´‡∏≤‡∏Å‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‡πÉ‡∏´‡πâ‡∏ï‡∏≠‡∏ö‡∏ß‡πà‡∏≤ "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á" ‡πÅ‡∏•‡∏∞‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô‡∏à‡∏≤‡∏Å‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏¥‡∏ï‡∏£ ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÅ‡∏à‡πâ‡∏á‡∏ß‡πà‡∏≤‡∏ô‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏à‡∏≤‡∏Å AI

    ‡πÇ‡∏õ‡∏£‡∏î‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡πÄ‡∏õ‡πá‡∏ô HTML ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö‡πÅ‡∏ä‡∏ó ‡πÇ‡∏î‡∏¢‡∏Ñ‡∏á‡∏Ç‡∏ô‡∏≤‡∏î‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£‡πÉ‡∏´‡πâ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏° ‡πÅ‡∏•‡∏∞‡∏û‡∏π‡∏î‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Ñ‡∏∏‡∏ì‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Ñ‡∏∏‡∏¢‡∏Å‡∏±‡∏ö‡∏Ñ‡∏ô‡∏à‡∏£‡∏¥‡∏á ‡πÜ
    """

    prompt = f"""
    <‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á>
    {context}
    </‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á>

    <‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡∏Å‡πà‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤>
    {chat_history}
    </‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡∏Å‡πà‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤>

    <‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°>
    {question}
    </‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°>
    """
    try:
        response = client.chat.completions.create(
            model="gpt-4.1",
            messages=[
                {"role": "system", "content": agentRole},
                {"role": "user", "content": prompt}
            ]
        )
        return str(response.choices[0].message.content).strip();
    except Exception as e:
        return f"‚ö†Ô∏è ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏Ç‡∏ì‡∏∞‡πÄ‡∏£‡∏µ‡∏¢‡∏Å Gemini API: {e}"
